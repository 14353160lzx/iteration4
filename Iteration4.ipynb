{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must be included at the beginning of each new notebook. Remember to change the app name.\n",
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Iteration4_ME').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data description\n",
    "## Overview of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---+-----------+-----------------+----------------+-------------------+----------+--------------+\n",
      "|D_no.|gender|age| Experience|High_speed_acc_lv|Low_speed_acc_lv|High_speed_deacc_lv|aggressive|motor_emission|\n",
      "+-----+------+---+-----------+-----------------+----------------+-------------------+----------+--------------+\n",
      "|    1|  male| 37|experienced|                0|               0|                  0|         0|   0.405752109|\n",
      "|    2|  male| 26|experienced|                0|               0|                  0|         0|   0.420112566|\n",
      "|    3|female| 51|experienced|                0|               0|                  0|         0|   0.384248646|\n",
      "|    4|  male| 48|    novince|                0|               0|                  1|         1|   0.483147426|\n",
      "|    5|  male| 26|experienced|                1|               0|               null|         0|   0.444735788|\n",
      "|    6|  male| 58|    novince|                1|               0|                  1|         1|   0.525062254|\n",
      "|    7|female| 24|    novince|                1|            null|                  1|         0|    0.48444717|\n",
      "|    8|female| 47|experienced|                0|               0|                  0|         0|   0.405924972|\n",
      "|    9|  male| 28|experienced|                1|               0|               null|         0|   0.440848256|\n",
      "|   10|  male| 25|experienced|                0|               0|                  0|         0|   0.403779716|\n",
      "|   11|  male| 24|experienced|                0|               0|                  0|         0|   0.415305164|\n",
      "|   12|  male| 25|experienced|                0|               0|                  0|         0|   0.409683008|\n",
      "|   13|  male| 38|experienced|                0|               0|                  0|         0|   0.388998558|\n",
      "|   14|  male| 38|experienced|                1|               0|                  0|         0|   0.470359014|\n",
      "|   15|  male| 37|experienced|                0|               0|                  0|         0|   0.389981229|\n",
      "|   16|female| 40|experienced|                0|               0|                  0|         0|   0.417141486|\n",
      "|   17|  male| 34|experienced|                0|               0|                  0|         0|   0.416627666|\n",
      "|   18|  male| 21|experienced|                1|               0|                  0|         0|   0.471383964|\n",
      "|   19|female| 56|experienced|                0|               0|                  0|         0|   0.403608113|\n",
      "|   20|  male| 36|experienced|                0|               0|                  0|         0|   0.398403256|\n",
      "+-----+------+---+-----------+-----------------+----------------+-------------------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load the dataset\n",
    "df = spark.read.csv('driver_charasteristic.csv', header=True, inferSchema=True)\n",
    "df.show()\n",
    "#df.columns\n",
    "#df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features of datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- No: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- Experience: string (nullable = true)\n",
      " |-- High_speed_acc_lv: integer (nullable = true)\n",
      " |-- Low_speed_acc_lv: integer (nullable = true)\n",
      " |-- High_speed_deacc_lv: integer (nullable = true)\n",
      " |-- aggressive: integer (nullable = true)\n",
      " |-- motor_emission: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#data type\n",
    "df = df.withColumnRenamed(\"D_no.\",\"No\") #Feature name D_no. may cause functional error of the program which has to be renamed.\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-------------+-------------------+\n",
      "|gender|aggressive|count(gender)|avg(motor_emission)|\n",
      "+------+----------+-------------+-------------------+\n",
      "|  null|      null|            0|               null|\n",
      "|female|      null|            4|       0.4429964275|\n",
      "|  male|         0|          320| 0.4378172056218754|\n",
      "|  male|      null|            4|      0.44855222725|\n",
      "|female|         1|           41|        0.591457677|\n",
      "|female|         0|          147| 0.4335012906530611|\n",
      "|  male|         1|          141| 0.6529134100851062|\n",
      "+------+----------+-------------+-------------------+\n",
      "\n",
      "+------+----------+-------------+-------------------+\n",
      "|gender|aggressive|count(gender)|avg(motor_emission)|\n",
      "+------+----------+-------------+-------------------+\n",
      "|  male|         0|          320| 0.4378172056218754|\n",
      "|female|         1|           41|        0.591457677|\n",
      "|female|         0|          147| 0.4335012906530611|\n",
      "|  male|         1|          141| 0.6529134100851062|\n",
      "+------+----------+-------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#data exploration\n",
    "#Initialize the data table for sql query\n",
    "df.createOrReplaceTempView('ME')\n",
    "#aggressive and gender\n",
    "results = spark.sql(\"select gender,aggressive,count(gender),mean(motor_emission) from ME group by gender,aggressive\")\n",
    "results.show()\n",
    "results.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------------+---------------------+------------------------+-----------------+-------------------+\n",
      "|aggressive|avg(High_speed_acc_lv)|avg(Low_speed_acc_lv)|avg(High_speed_deacc_lv)|count(aggressive)|avg(motor_emission)|\n",
      "+----------+----------------------+---------------------+------------------------+-----------------+-------------------+\n",
      "|      null|                  0.25|   0.3333333333333333|                    0.75|                0|0.44577432737499995|\n",
      "|         1|    0.9010989010989011|   0.9195402298850575|      0.9395604395604396|              182| 0.6390689866978023|\n",
      "|         0|    0.2039045553145336| 0.030534351145038167|     0.47956989247311826|              467|0.43645866279443274|\n",
      "+----------+----------------------+---------------------+------------------------+-----------------+-------------------+\n",
      "\n",
      "+----------+----------------------+---------------------+------------------------+-----------------+-------------------+\n",
      "|aggressive|avg(High_speed_acc_lv)|avg(Low_speed_acc_lv)|avg(High_speed_deacc_lv)|count(aggressive)|avg(motor_emission)|\n",
      "+----------+----------------------+---------------------+------------------------+-----------------+-------------------+\n",
      "|         1|    0.9010989010989011|   0.9195402298850575|      0.9395604395604396|              182| 0.6390689866978023|\n",
      "|         0|    0.2039045553145336| 0.030534351145038167|     0.47956989247311826|              467|0.43645866279443274|\n",
      "+----------+----------------------+---------------------+------------------------+-----------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#aggrissive and acceleration rate\n",
    "results = spark.sql(\"select aggressive,mean(High_speed_acc_lv),mean(Low_speed_acc_lv),mean(High_speed_deacc_lv),\\\n",
    "                        count(aggressive),mean(motor_emission) from ME group by aggressive\")\n",
    "results.show()\n",
    "results.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------------+---------------------+------------------------+-----------------+-------------------+\n",
      "| Experience|avg(High_speed_acc_lv)|avg(Low_speed_acc_lv)|avg(High_speed_deacc_lv)|count(Experience)|avg(motor_emission)|\n",
      "+-----------+----------------------+---------------------+------------------------+-----------------+-------------------+\n",
      "|    novince|   0.15217391304347827| 0.061224489795918366|      0.9700854700854701|              234|0.45611803235897436|\n",
      "|       null|                  null|                  1.0|                    null|                0|               null|\n",
      "|experienced|    0.5344418052256532|   0.3862559241706161|     0.41092636579572445|              423| 0.5129345771891256|\n",
      "+-----------+----------------------+---------------------+------------------------+-----------------+-------------------+\n",
      "\n",
      "+-----------+----------------------+---------------------+------------------------+-----------------+-------------------+\n",
      "| Experience|avg(High_speed_acc_lv)|avg(Low_speed_acc_lv)|avg(High_speed_deacc_lv)|count(Experience)|avg(motor_emission)|\n",
      "+-----------+----------------------+---------------------+------------------------+-----------------+-------------------+\n",
      "|    novince|   0.15217391304347827| 0.061224489795918366|      0.9700854700854701|              234|0.45611803235897436|\n",
      "|experienced|    0.5344418052256532|   0.3862559241706161|     0.41092636579572445|              423| 0.5129345771891256|\n",
      "+-----------+----------------------+---------------------+------------------------+-----------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#experience and acceleration rate\n",
    "results = spark.sql(\"select Experience,mean(High_speed_acc_lv),mean(Low_speed_acc_lv),mean(High_speed_deacc_lv),\\\n",
    "                        count(Experience),mean(motor_emission) from ME group by Experience\")\n",
    "results.show()\n",
    "results.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------------+---------------------+------------------------+----------+-------------------+\n",
      "|          avg(age)|avg(High_speed_acc_lv)|avg(Low_speed_acc_lv)|avg(High_speed_deacc_lv)|count(age)|avg(motor_emission)|\n",
      "+------------------+----------------------+---------------------+------------------------+----------+-------------------+\n",
      "|29.965675057208237|    0.5127020785219399|  0.41225626740947074|      0.5310344827586206|       437| 0.5104570789450803|\n",
      "+------------------+----------------------+---------------------+------------------------+----------+-------------------+\n",
      "\n",
      "+-----------------+----------------------+---------------------+------------------------+----------+-------------------+\n",
      "|         avg(age)|avg(High_speed_acc_lv)|avg(Low_speed_acc_lv)|avg(High_speed_deacc_lv)|count(age)|avg(motor_emission)|\n",
      "+-----------------+----------------------+---------------------+------------------------+----------+-------------------+\n",
      "|50.46560846560847|   0.14285714285714285|  0.08064516129032258|       0.783068783068783|       189|0.45087004078835974|\n",
      "+-----------------+----------------------+---------------------+------------------------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#age and acceleration rate\n",
    "results1 = spark.sql(\"select mean(age),mean(High_speed_acc_lv),mean(Low_speed_acc_lv),mean(High_speed_deacc_lv),\\\n",
    "                        count(age),mean(motor_emission) from ME where age < 40\")\n",
    "results1.show()\n",
    "results2 = spark.sql(\"select mean(age),mean(High_speed_acc_lv),mean(Low_speed_acc_lv),mean(High_speed_deacc_lv),\\\n",
    "                        count(age),mean(motor_emission) from ME where age > 40\")\n",
    "results2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data quality\n",
    "### Null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|gender|count|\n",
      "+------+-----+\n",
      "|  null|    3|\n",
      "|female|  192|\n",
      "|  male|  465|\n",
      "+------+-----+\n",
      "\n",
      "+-----------+-----+\n",
      "| Experience|count|\n",
      "+-----------+-----+\n",
      "|    novince|  234|\n",
      "|       null|    3|\n",
      "|experienced|  423|\n",
      "+-----------+-----+\n",
      "\n",
      "+----------+-----+\n",
      "|aggressive|count|\n",
      "+----------+-----+\n",
      "|      null|   11|\n",
      "|         1|  182|\n",
      "|         0|  467|\n",
      "+----------+-----+\n",
      "\n",
      "0\n",
      "+-----------------+-----+\n",
      "|High_speed_acc_lv|count|\n",
      "+-----------------+-----+\n",
      "|             null|    9|\n",
      "|                1|  260|\n",
      "|                0|  391|\n",
      "+-----------------+-----+\n",
      "\n",
      "+----------------+-----+\n",
      "|Low_speed_acc_lv|count|\n",
      "+----------------+-----+\n",
      "|            null|   90|\n",
      "|               1|  173|\n",
      "|               0|  397|\n",
      "+----------------+-----+\n",
      "\n",
      "+-------------------+-----+\n",
      "|High_speed_deacc_lv|count|\n",
      "+-------------------+-----+\n",
      "|               null|    5|\n",
      "|                  1|  400|\n",
      "|                  0|  255|\n",
      "+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#show the number of different instances\n",
    "df.groupBy('gender').count().show()\n",
    "df.groupBy('Experience').count().show()\n",
    "df.groupBy('aggressive').count().show()\n",
    "print(df.filter('motor_emission = null').count())\n",
    "df.groupBy('High_speed_acc_lv').count().show()\n",
    "df.groupBy('Low_speed_acc_lv').count().show()\n",
    "df.groupBy('High_speed_deacc_lv').count().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df.filter('motor_emission < 0 or motor_emission > 1').count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+-----------+-----------------+----------------+-------------------+----------+--------------+\n",
      "| No|gender|age| Experience|High_speed_acc_lv|Low_speed_acc_lv|High_speed_deacc_lv|aggressive|motor_emission|\n",
      "+---+------+---+-----------+-----------------+----------------+-------------------+----------+--------------+\n",
      "|  1|  male| 37|experienced|                0|               0|                  0|         0|   0.405752109|\n",
      "|  2|  male| 26|experienced|                0|               0|                  0|         0|   0.420112566|\n",
      "|  3|female| 51|experienced|                0|               0|                  0|         0|   0.384248646|\n",
      "|  4|  male| 48|    novince|                0|               0|                  1|         1|   0.483147426|\n",
      "|  6|  male| 58|    novince|                1|               0|                  1|         1|   0.525062254|\n",
      "|  8|female| 47|experienced|                0|               0|                  0|         0|   0.405924972|\n",
      "| 10|  male| 25|experienced|                0|               0|                  0|         0|   0.403779716|\n",
      "| 11|  male| 24|experienced|                0|               0|                  0|         0|   0.415305164|\n",
      "| 12|  male| 25|experienced|                0|               0|                  0|         0|   0.409683008|\n",
      "| 13|  male| 38|experienced|                0|               0|                  0|         0|   0.388998558|\n",
      "| 14|  male| 38|experienced|                1|               0|                  0|         0|   0.470359014|\n",
      "| 15|  male| 37|experienced|                0|               0|                  0|         0|   0.389981229|\n",
      "| 16|female| 40|experienced|                0|               0|                  0|         0|   0.417141486|\n",
      "| 17|  male| 34|experienced|                0|               0|                  0|         0|   0.416627666|\n",
      "| 18|  male| 21|experienced|                1|               0|                  0|         0|   0.471383964|\n",
      "| 19|female| 56|experienced|                0|               0|                  0|         0|   0.403608113|\n",
      "| 20|  male| 36|experienced|                0|               0|                  0|         0|   0.398403256|\n",
      "| 21|  male| 31|experienced|                0|               0|                  0|         0|   0.414839511|\n",
      "| 22|  male| 31|experienced|                0|               0|                  0|         0|   0.421422323|\n",
      "| 23|  male| 28|experienced|                0|               0|                  0|         0|    0.41827233|\n",
      "+---+------+---+-----------+-----------------+----------------+-------------------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "563\n"
     ]
    }
   ],
   "source": [
    "#droup all instance with null values\n",
    "df = df.na.drop()\n",
    "df.show()\n",
    "print(df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+-----------+-----------+\n",
      "|gender|gender_int| Experience|Experienced|\n",
      "+------+----------+-----------+-----------+\n",
      "|  male|         1|experienced|          1|\n",
      "|  male|         1|experienced|          1|\n",
      "|female|         0|experienced|          1|\n",
      "|  male|         1|    novince|          0|\n",
      "|  male|         1|    novince|          0|\n",
      "|female|         0|experienced|          1|\n",
      "|  male|         1|experienced|          1|\n",
      "|  male|         1|experienced|          1|\n",
      "|  male|         1|experienced|          1|\n",
      "|  male|         1|experienced|          1|\n",
      "|  male|         1|experienced|          1|\n",
      "|  male|         1|experienced|          1|\n",
      "|female|         0|experienced|          1|\n",
      "|  male|         1|experienced|          1|\n",
      "|  male|         1|experienced|          1|\n",
      "|female|         0|experienced|          1|\n",
      "|  male|         1|experienced|          1|\n",
      "|  male|         1|experienced|          1|\n",
      "|  male|         1|experienced|          1|\n",
      "|  male|         1|experienced|          1|\n",
      "+------+----------+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "#Reconstruct feature from string to flag\n",
    "new_df = df.withColumn(\"Experienced\", F.when(df[\"Experience\"] == \"experienced\",1).otherwise(0))\n",
    "new_df = new_df.withColumn(\"gender_int\", F.when(df[\"gender\"] == \"male\",1).otherwise(0))\n",
    "new_df.select(['gender','gender_int','Experience','Experienced']).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## example of data integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+\n",
      "| No|gender|age|\n",
      "+---+------+---+\n",
      "|  1|  male| 37|\n",
      "+---+------+---+\n",
      "only showing top 1 row\n",
      "\n",
      "+---+------+-----------+\n",
      "|No2|gender| Experience|\n",
      "+---+------+-----------+\n",
      "|  1|  male|experienced|\n",
      "+---+------+-----------+\n",
      "only showing top 1 row\n",
      "\n",
      "+---+------+---+-----------+\n",
      "| No|gender|age| Experience|\n",
      "+---+------+---+-----------+\n",
      "|  1|  male| 37|experienced|\n",
      "+---+------+---+-----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = df.select(['No','gender','age'])\n",
    "df2 = df.select(['No','gender','Experience']).withColumnRenamed(\"No\",\"No2\")\n",
    "Int_df = df1.join(df2.drop('gender'), df1[\"No\"] == df2[\"No2\"],\"leftouter\").drop('No2')\n",
    "df1.show(1)\n",
    "df2.show(1)\n",
    "Int_df.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformation\n",
    "## Reduce the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+----------------+-------------------+----------+--------------+-----------+----------+\n",
      "|age|High_speed_acc_lv|Low_speed_acc_lv|High_speed_deacc_lv|aggressive|motor_emission|Experienced|gender_int|\n",
      "+---+-----------------+----------------+-------------------+----------+--------------+-----------+----------+\n",
      "| 37|                0|               0|                  0|         0|   0.405752109|          1|         1|\n",
      "| 26|                0|               0|                  0|         0|   0.420112566|          1|         1|\n",
      "| 51|                0|               0|                  0|         0|   0.384248646|          1|         0|\n",
      "| 48|                0|               0|                  1|         1|   0.483147426|          0|         1|\n",
      "+---+-----------------+----------------+-------------------+----------+--------------+-----------+----------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df = new_df.drop('No','gender','Experience')\n",
    "new_df.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+\n",
      "|age|normalized_age|\n",
      "+---+--------------+\n",
      "| 37|         0.425|\n",
      "| 26|          0.15|\n",
      "| 51|         0.775|\n",
      "| 48|           0.7|\n",
      "| 58|          0.95|\n",
      "| 47|         0.675|\n",
      "| 25|         0.125|\n",
      "| 24|           0.1|\n",
      "| 25|         0.125|\n",
      "| 38|          0.45|\n",
      "+---+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#data normalization\n",
    "new_df = new_df.withColumn('normalized_age',(new_df['age'] - 20)/40)\n",
    "new_df.select('age','normalized_age').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+-------------------+----------+--------------+-----------+----------+--------------+\n",
      "|High_speed_acc_lv|Low_speed_acc_lv|High_speed_deacc_lv|aggressive|motor_emission|Experienced|gender_int|normalized_age|\n",
      "+-----------------+----------------+-------------------+----------+--------------+-----------+----------+--------------+\n",
      "|                0|               0|                  0|         0|   0.405752109|          1|         1|         0.425|\n",
      "|                0|               0|                  0|         0|   0.420112566|          1|         1|          0.15|\n",
      "|                0|               0|                  0|         0|   0.384248646|          1|         0|         0.775|\n",
      "|                0|               0|                  1|         1|   0.483147426|          0|         1|           0.7|\n",
      "|                1|               0|                  1|         1|   0.525062254|          0|         1|          0.95|\n",
      "|                0|               0|                  0|         0|   0.405924972|          1|         0|         0.675|\n",
      "|                0|               0|                  0|         0|   0.403779716|          1|         1|         0.125|\n",
      "|                0|               0|                  0|         0|   0.415305164|          1|         1|           0.1|\n",
      "|                0|               0|                  0|         0|   0.409683008|          1|         1|         0.125|\n",
      "|                0|               0|                  0|         0|   0.388998558|          1|         1|          0.45|\n",
      "+-----------------+----------------+-------------------+----------+--------------+-----------+----------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#drop the age column afterwards\n",
    "new_df = new_df.drop('age')\n",
    "new_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spliting dataset (test design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n",
      "|            features|motor_emission|\n",
      "+--------------------+--------------+\n",
      "|(7,[4,5,6],[1.0,1...|   0.405752109|\n",
      "|(7,[4,5,6],[1.0,1...|   0.420112566|\n",
      "|(7,[4,6],[1.0,0.7...|   0.384248646|\n",
      "|[0.0,0.0,1.0,1.0,...|   0.483147426|\n",
      "|[1.0,0.0,1.0,1.0,...|   0.525062254|\n",
      "|(7,[4,6],[1.0,0.6...|   0.405924972|\n",
      "|(7,[4,5,6],[1.0,1...|   0.403779716|\n",
      "|(7,[4,5,6],[1.0,1...|   0.415305164|\n",
      "|(7,[4,5,6],[1.0,1...|   0.409683008|\n",
      "|(7,[4,5,6],[1.0,1...|   0.388998558|\n",
      "|[1.0,0.0,0.0,0.0,...|   0.470359014|\n",
      "|(7,[4,5,6],[1.0,1...|   0.389981229|\n",
      "| (7,[4,6],[1.0,0.5])|   0.417141486|\n",
      "|(7,[4,5,6],[1.0,1...|   0.416627666|\n",
      "|[1.0,0.0,0.0,0.0,...|   0.471383964|\n",
      "| (7,[4,6],[1.0,0.9])|   0.403608113|\n",
      "|(7,[4,5,6],[1.0,1...|   0.398403256|\n",
      "|(7,[4,5,6],[1.0,1...|   0.414839511|\n",
      "|(7,[4,5,6],[1.0,1...|   0.421422323|\n",
      "|(7,[4,5,6],[1.0,1...|    0.41827233|\n",
      "+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"High_speed_acc_lv\",\"Low_speed_acc_lv\",\"High_speed_deacc_lv\",\"aggressive\",\n",
    "               \"Experienced\", \"gender_int\", \"normalized_age\"],\n",
    "    outputCol=\"features\")\n",
    "Data = assembler.transform(new_df).select('features','motor_emission')\n",
    "\n",
    "(trainingData, testData) = Data.randomSplit([0.7, 0.3])\n",
    "Data.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm selection\n",
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------+--------------------+\n",
      "|        prediction|motor_emission|            features|\n",
      "+------------------+--------------+--------------------+\n",
      "|0.4563311661440176|    0.47321014|(7,[0,4,6],[1.0,1...|\n",
      "|0.4384319109217586|   0.429330792|(7,[2,4,6],[1.0,1...|\n",
      "|0.4442057339399915|   0.432475948|(7,[2,5,6],[1.0,1...|\n",
      "|0.4435586176997999|   0.428169933|(7,[2,5,6],[1.0,1...|\n",
      "|0.4435586176997999|    0.43451568|(7,[2,5,6],[1.0,1...|\n",
      "+------------------+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.00961122\n",
      "Coefficient of determination (r2) on test data = 0.992111\n",
      "Coefficients: [0.04979396869409326,0.1268075735796198,0.04127789895461277,0.038793129489470904,0.0005910051138420696,0.0008643400904461856,-0.012942324803832367]\n",
      "Intercept: 0.4082110991767529\n",
      "numIterations: 1\n",
      "objectiveHistory: [0.0]\n",
      "+--------------------+\n",
      "|           residuals|\n",
      "+--------------------+\n",
      "|-0.01109971650430...|\n",
      "|8.040754956950003E-4|\n",
      "|0.002036332696653...|\n",
      "|0.014371168297132142|\n",
      "|-0.00702794914963...|\n",
      "|-0.00112466174772...|\n",
      "|0.014191628276804202|\n",
      "|-0.00852654136290...|\n",
      "|0.003339296597858...|\n",
      "|-2.43565801662848...|\n",
      "|0.001498265198337...|\n",
      "|0.005809258859050426|\n",
      "|0.011153633979146205|\n",
      "|0.004753612219337844|\n",
      "|0.004645379339433653|\n",
      "|-0.01385890754047...|\n",
      "|-0.01057359006008729|\n",
      "|-0.00396671381989...|\n",
      "|4.612201801043047...|\n",
      "|0.009297030180104304|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "RMSE: 0.009701\n",
      "r2: 0.991332\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "#initialize linear regression model\n",
    "#lr = LinearRegression(labelCol='motor_emission')\n",
    "lr = LinearRegression(maxIter=100, regParam=0.001, elasticNetParam= 0,labelCol='motor_emission')\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = lrModel.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"motor_emission\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator1 = RegressionEvaluator(\n",
    "    labelCol=\"motor_emission\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator1.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "evaluator2 = RegressionEvaluator(\n",
    "    labelCol=\"motor_emission\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator2.evaluate(predictions)\n",
    "print(\"Coefficient of determination (r2) on test data = %g\" % r2)\n",
    "\n",
    "# Print the coefficients and intercept for linear regression\n",
    "print(\"Coefficients: %s\" % str(lrModel.coefficients))\n",
    "print(\"Intercept: %s\" % str(lrModel.intercept))\n",
    "\n",
    "# Summarize the model over the training set and print out some metrics\n",
    "trainingSummary = lrModel.summary\n",
    "print(\"numIterations: %d\" % trainingSummary.totalIterations)\n",
    "print(\"objectiveHistory: %s\" % str(trainingSummary.objectiveHistory))\n",
    "trainingSummary.residuals.show()\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------+--------------------+\n",
      "|        prediction|motor_emission|            features|\n",
      "+------------------+--------------+--------------------+\n",
      "|0.4547447904615386|    0.47321014|(7,[0,4,6],[1.0,1...|\n",
      "|0.4392407436901409|   0.429330792|(7,[2,4,6],[1.0,1...|\n",
      "|0.4491940985789473|   0.432475948|(7,[2,5,6],[1.0,1...|\n",
      "|0.4491940985789473|   0.428169933|(7,[2,5,6],[1.0,1...|\n",
      "|0.4491940985789473|    0.43451568|(7,[2,5,6],[1.0,1...|\n",
      "+------------------+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.0107048\n",
      "Coefficient of determination (r2) on test data = 0.990214\n",
      "DecisionTreeRegressionModel (uid=DecisionTreeRegressor_4e5fb7b95c3b72a40d9e) of depth 5 with 57 nodes\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "\n",
    "# Train a DecisionTree model.\n",
    "dt = DecisionTreeRegressor(labelCol=\"motor_emission\")\n",
    "\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "model = dt.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"motor_emission\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "rmse = evaluator1.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "r2 = evaluator2.evaluate(predictions)\n",
    "print(\"Coefficient of determination (r2) on test data = %g\" % r2)\n",
    "\n",
    "\n",
    "print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+--------------------+\n",
      "|         prediction|motor_emission|            features|\n",
      "+-------------------+--------------+--------------------+\n",
      "|0.45418483330846293|    0.47321014|(7,[0,4,6],[1.0,1...|\n",
      "|  0.429660241884157|   0.429330792|(7,[2,4,6],[1.0,1...|\n",
      "|0.43984804383381687|   0.432475948|(7,[2,5,6],[1.0,1...|\n",
      "|0.44108560802534635|   0.428169933|(7,[2,5,6],[1.0,1...|\n",
      "|0.44108560802534635|    0.43451568|(7,[2,5,6],[1.0,1...|\n",
      "+-------------------+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.011199\n",
      "Coefficient of determination (r2) on test data = 0.98929\n",
      "Root Mean Squared Error (RMSE) on test data = 0.011199\n",
      "RandomForestRegressionModel (uid=rfr_4ef77217b43e) with 20 trees\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestRegressor(labelCol=\"motor_emission\")\n",
    "\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "model = rf.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"motor_emission\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "rmse = evaluator1.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "r2 = evaluator2.evaluate(predictions)\n",
    "print(\"Coefficient of determination (r2) on test data = %g\" % r2)\n",
    "\n",
    "print(model)  # summary only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient-boosted tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+--------------------+\n",
      "|         prediction|motor_emission|            features|\n",
      "+-------------------+--------------+--------------------+\n",
      "|  0.450266597913837|    0.47321014|(7,[0,4,6],[1.0,1...|\n",
      "| 0.4388988716361566|   0.429330792|(7,[2,4,6],[1.0,1...|\n",
      "|0.44963472549061534|   0.432475948|(7,[2,5,6],[1.0,1...|\n",
      "|0.44963472549061534|   0.428169933|(7,[2,5,6],[1.0,1...|\n",
      "|0.44963472549061534|    0.43451568|(7,[2,5,6],[1.0,1...|\n",
      "+-------------------+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 0.0111245\n",
      "Coefficient of determination (r2) on test data = 0.989432\n",
      "GBTRegressionModel (uid=GBTRegressor_40bdad18a1904adabdaf) with 10 trees\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "\n",
    "# Train a GBT model.\n",
    "gbt = GBTRegressor(labelCol=\"motor_emission\", maxIter=10)\n",
    "\n",
    "\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "model = gbt.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"motor_emission\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "rmse = evaluator1.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "r2 = evaluator2.evaluate(predictions)\n",
    "print(\"Coefficient of determination (r2) on test data = %g\" % r2)\n",
    "\n",
    "print(model)  # summary only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "+-------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|  High_speed_acc_lv|  Low_speed_acc_lv|High_speed_deacc_lv|          aggressive|         Experienced|          gender_int|      normalized_age|\n",
      "+-------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|0.04979396869409326|0.1268075735796198|0.04127789895461277|0.038793129489470904|5.910051138420696E-4|8.643400904461856E-4|-0.01294232480383...|\n",
      "+-------------------+------------------+-------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the relevant Python libraries.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "coffi_tup = tuple(lrModel.coefficients.tolist())\n",
    "\n",
    "print(type(coffi_tup))\n",
    "# Convert sex to an array using Numpy and plot it using pyplot\n",
    "coffi = spark.createDataFrame([coffi_tup], (\"High_speed_acc_lv\",\"Low_speed_acc_lv\",\"High_speed_deacc_lv\",\"aggressive\", \"Experienced\", \"gender_int\", \"normalized_age\"))\n",
    "coffi.show()\n",
    "sexArr = np.array(coffi.collect())\n",
    "plt.hist(sexArr)\n",
    "plt.show()\n",
    "\n",
    "# Because you can interact with Spark using SQL, you can also filter the data you see. \n",
    "# For example, age has some null values. We can remove all null values before visualising the data.\n",
    "#ageArr = np.array(data.filter('Age > 0').select('Age').collect())\n",
    "#plt.hist(ageArr)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
